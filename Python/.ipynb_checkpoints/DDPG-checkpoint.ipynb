{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up working directory\n",
    "import os\n",
    "os.chdir(\"E:/unity/ml-agents/ml-agents-envs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = None  # Name of the Unity environment binary to launch\n",
    "train_mode = True  # Whether to run the environment in training or inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:\n",
      "3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfig, EngineConfigurationChannel\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Python version:\")\n",
    "print(sys.version)\n",
    "\n",
    "# check Python version\n",
    "if (sys.version_info[0] < 3):\n",
    "    raise Exception(\"ERROR: ML-Agents Toolkit (v0.3 onwards) requires Python 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlagents_envs:Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "INFO:mlagents_envs:Connected new brain:\n",
      "Panda Agent?team=0\n"
     ]
    }
   ],
   "source": [
    "engine_configuration_channel = EngineConfigurationChannel()\n",
    "env = UnityEnvironment(base_port = 5004, file_name=None, side_channels = [engine_configuration_channel])\n",
    "\n",
    "#Reset the environment\n",
    "env.reset()\n",
    "\n",
    "# Set the default brain to work with\n",
    "group_name = env.get_agent_groups()[0]\n",
    "group_spec = env.get_agent_group_spec(group_name)\n",
    "\n",
    "# Set the time scale of the engine\n",
    "engine_configuration_channel.set_configuration_parameters(time_scale = 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Panda Agent?team=0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :  1\n",
      "Agent state looks like: \n",
      "[[0.829      0.1385     0.         0.         0.5        0.5\n",
      "  1.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.        ]\n",
      " [0.59430003 0.4765     0.         0.         0.5        0.5\n",
      "  1.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.        ]\n",
      " [0.1286     0.26549998 0.         0.         0.5        0.5\n",
      "  1.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.        ]\n",
      " [0.7585     0.1385     0.         0.         0.5        0.5\n",
      "  1.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.        ]\n",
      " [0.45299998 0.704      0.         0.         0.5        0.5\n",
      "  1.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.        ]\n",
      " [0.0513     0.1604     0.         0.         0.5        0.5\n",
      "  1.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.        ]\n",
      " [0.741      0.4765     0.         0.         0.5        0.5\n",
      "  1.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.        ]\n",
      " [0.32275    0.26549998 0.         0.         0.5        0.5\n",
      "  1.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.        ]]\n",
      "Agent state looks like: \n",
      "[0.829  0.1385 0.     0.     0.5    0.5    1.     0.     0.     1.\n",
      " 0.     0.     0.     0.     0.     1.     0.    ]\n",
      "Is there a visual observation ? False\n"
     ]
    }
   ],
   "source": [
    "# Get the state of the agents\n",
    "step_result = env.get_step_result(group_name)\n",
    "\n",
    "# Examine the number of observations per Agent\n",
    "print(\"Number of observations : \", len(group_spec.observation_shapes))\n",
    "\n",
    "# Examine the state space for the first observation for all agents\n",
    "print(\"Agent state looks like: \\n{}\".format(step_result.obs[0]))\n",
    "\n",
    "# Examine the state space for the first observation for the first agent\n",
    "print(\"Agent state looks like: \\n{}\".format(step_result.obs[0][0]))\n",
    "\n",
    "# Is there a visual observation ?\n",
    "vis_obs = any([len(shape) == 3 for shape in group_spec.observation_shapes])\n",
    "print(\"Is there a visual observation ?\", vis_obs)\n",
    "\n",
    "# Examine the visual observations\n",
    "if vis_obs:\n",
    "    vis_obs_index = next(i for i,v in enumerate(group_spec.observation_shapes) if len(v) == 3)\n",
    "    print(\"Agent visual observation look like:\")\n",
    "    obs = step_result.obs[vis_obs_index]\n",
    "    plt.imshow(obs[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import deque, namedtuple\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=256, fc2_units=128):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        #self.reset_parameters()\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "#         self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "#         self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fcs1_units=256, fc2_units=128):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fcs1_units)\n",
    "        self.fc2 = nn.Linear(fcs1_units+action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 1)\n",
    "        #self.reset_parameters()\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "#         self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "#         self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        xs = F.relu(self.fcs1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if CPU or GPU computation should be used\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 32        # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4         # learning rate of the actor \n",
    "LR_CRITIC = 1e-4       # learning rate of the critic\n",
    "WEIGHT_DECAY = 0.0      # L2 weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, num_agents, random_seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.num_agents = num_agents\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Noise process for each agent\n",
    "        self.noise = OUNoise((num_agents, action_size), random_seed)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "    \n",
    "    def step(self, states, actions, rewards, next_states, dones):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        for agent in range(self.num_agents):\n",
    "            self.memory.add(states[agent,:], actions[agent,:], rewards[agent], next_states[agent,:], dones[agent])\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences)\n",
    "\n",
    "    def act(self, state, add_noise=True, scale = 2):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        acts = np.zeros((self.num_agents, self.action_size))\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            for agent in range(self.num_agents):\n",
    "                acts[agent,:] = self.actor_local(state[agent,:]).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            acts += scale * self.noise.sample()\n",
    "        return np.clip(acts, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (GAMMA * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm(self.critic_local.parameters(), 1)\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0.0, theta=0.15, sigma=0.15, sigma_min = 0.05, sigma_decay=.975):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_decay = sigma_decay\n",
    "        self.seed = random.seed(seed)\n",
    "        self.size = size\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "        \"\"\"Resduce  sigma from initial value to min\"\"\"\n",
    "        self.sigma = max(self.sigma_min, self.sigma*self.sigma_decay)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.standard_normal(self.size)\n",
    "        self.state = x + dx\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = group_spec.action_shape\n",
    "state_size = group_spec.observation_shapes[0][0]\n",
    "num_agents = len(step_result.obs[0])\n",
    "\n",
    "episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, num_agents=num_agents, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.5262495077913627\n",
      "1 -0.9462494611507282\n",
      "2 -0.8587494480889291\n",
      "3 -0.5187495144782588\n",
      "4 -0.5737495055655017\n",
      "5 -0.8162494619027711\n",
      "6 -0.6487494906177744\n",
      "7 -1.0037494516000152\n",
      "8 -0.7937494574580342\n",
      "9 -0.5349995022406802\n",
      "10 -0.5687495087040588\n",
      "11 -0.6162494987947866\n",
      "12 -0.7324994656955823\n",
      "13 -1.1049994202330709\n",
      "14 -0.8737494545057416\n",
      "15 -0.5412495018681511\n",
      "16 -1.0274994438514113\n",
      "17 -0.8712494487408549\n",
      "18 -0.3612495008856058\n",
      "19 0.007500411244109273\n",
      "20 -0.6124995091813616\n",
      "21 -1.1049994202330709\n",
      "22 -1.1049994202330709\n",
      "23 -1.1049994202330709\n",
      "24 -0.7587494561448693\n",
      "25 -0.5874994819751009\n",
      "26 -0.698749462608248\n",
      "27 -0.6862494759261608\n",
      "28 -0.5362495047738776\n",
      "29 -0.5849994950694963\n",
      "30 -0.5824995037401095\n",
      "31 -0.5587494954233989\n",
      "32 -0.7587494561448693\n",
      "33 -0.709999484475702\n",
      "34 -0.8237494621425867\n",
      "35 -0.7612494742497802\n",
      "36 -0.34499950846657157\n",
      "37 -1.1049994202330709\n",
      "38 -1.1049994202330709\n",
      "39 -1.1049994202330709\n",
      "40 -1.1049994202330709\n",
      "41 -0.7699994593858719\n",
      "42 -0.7649994806852192\n",
      "43 -0.5549994989996776\n",
      "44 -0.5737494999775663\n",
      "45 -1.028749443590641\n",
      "46 -1.1049994202330709\n",
      "47 -1.1049994202330709\n",
      "48 -1.1049994202330709\n",
      "49 -1.1049994202330709\n",
      "50 -1.1049994202330709\n",
      "51 -1.0599994263611734\n",
      "52 -0.643749481998384\n",
      "53 -1.1049994202330709\n",
      "54 -1.1049994202330709\n",
      "55 -0.7699994593858719\n",
      "56 -0.4899995125597343\n",
      "57 -0.12499956914689392\n",
      "58 -0.25374953844584525\n",
      "59 -0.5324995185947046\n",
      "60 -0.5687494933372363\n",
      "61 -1.0137494439259171\n",
      "62 -1.0487494294065982\n",
      "63 -0.7749994662590325\n",
      "64 -0.5624994928948581\n",
      "65 -0.6949994786409661\n",
      "66 -1.1049994202330709\n",
      "67 -1.1049994202330709\n",
      "68 -0.7399994574952871\n",
      "69 -1.1049994202330709\n",
      "70 -0.7987494673579931\n",
      "71 -0.22999954351689667\n",
      "72 -0.10249957186169922\n",
      "73 -0.387499533186201\n",
      "74 -0.027499574061948806\n",
      "75 -0.6199994985363446\n",
      "76 -0.24874953035032377\n",
      "77 -0.8687494726618752\n",
      "78 -0.06999952998012304\n",
      "79 -0.13124954118393362\n",
      "80 -0.5024995186831802\n",
      "81 -0.489999515353702\n",
      "82 -0.7937494850484654\n",
      "83 -1.1049994202330709\n",
      "84 -0.7562494687736034\n",
      "85 -0.6624994724988937\n",
      "86 -0.7437494611367583\n",
      "87 -1.089999420568347\n",
      "88 -0.7849994720891118\n",
      "89 -0.4399995313724503\n",
      "90 -0.5149995073443279\n",
      "91 0.14250037295278162\n",
      "92 -0.31249953142832965\n",
      "93 -0.3449994991533458\n",
      "94 -0.6024994773324579\n",
      "95 -0.8299994603730738\n",
      "96 -1.0024994472041726\n",
      "97 -0.7212494612904266\n",
      "98 -0.9274994563311338\n",
      "99 -1.1049994202330709\n",
      "100 -0.9912494532763958\n",
      "101 -0.9537494454998523\n",
      "102 -0.7774994791252539\n",
      "103 -0.9399994408013299\n",
      "104 -0.37749955616891384\n",
      "105 -0.9487494449131191\n",
      "106 -0.8649994494626299\n",
      "107 -0.13749959925189614\n",
      "108 -0.5537494963500649\n",
      "109 -0.7762494804919697\n",
      "110 0.036250377423129976\n",
      "111 -0.5612495034001768\n",
      "112 -0.777499471383635\n",
      "113 -0.18374956265324727\n",
      "114 -0.6987494742497802\n",
      "115 -0.16124959150329232\n",
      "116 -0.5937495022080839\n",
      "117 -0.6999994768993929\n",
      "118 -0.5312495196703821\n",
      "119 -0.554999491199851\n",
      "120 -0.4549995136912912\n",
      "121 -0.23999956104671583\n",
      "122 -0.47624952939804643\n",
      "123 -0.2412495386088267\n",
      "124 0.47125035582575947\n",
      "125 -0.27999955869745463\n",
      "126 -0.9437494687736034\n",
      "127 -0.5749994920333847\n",
      "128 0.22250035381875932\n",
      "129 -0.3249995175283402\n",
      "130 -0.1824995629140176\n",
      "131 -0.10499960812740028\n",
      "132 0.1500004114350304\n",
      "133 0.03375039400998503\n",
      "134 0.08500041835941374\n",
      "135 -0.31374957371735945\n",
      "136 -0.33749956637620926\n",
      "137 -0.008749593049287796\n",
      "138 0.4525003716116771\n",
      "139 0.22750036069191992\n",
      "140 0.4725003563798964\n",
      "141 0.16750039055477828\n",
      "142 -0.25999955635052174\n",
      "143 -0.7537494717398658\n",
      "144 -0.12499957362888381\n",
      "145 0.2425004118704237\n",
      "146 0.09125037799822167\n",
      "147 0.11875041975872591\n",
      "148 0.3712503631832078\n",
      "149 0.6550003222655505\n",
      "150 0.9512502729194239\n",
      "151 0.2525003448827192\n",
      "152 0.6812502706889063\n",
      "153 0.23500038194470108\n",
      "154 -0.6137494773138314\n",
      "155 0.3050003999378532\n",
      "156 0.3325003763893619\n",
      "157 -0.03874959296081215\n",
      "158 -0.01249960612040013\n",
      "159 -0.11124959436710924\n",
      "160 0.06000041891820729\n",
      "161 0.16625037975609303\n",
      "162 0.7400002818903886\n",
      "163 -0.2787495265365578\n",
      "164 0.13500039151404053\n",
      "165 0.28750038822181523\n",
      "166 -0.5462494952371344\n",
      "167 0.45000035100383684\n",
      "168 -0.04499959445092827\n",
      "169 -0.19499953498598188\n",
      "170 0.3462503559421748\n",
      "171 -0.09499959257664159\n",
      "172 -0.22374955739360303\n",
      "173 0.07000040472485125\n",
      "174 -0.16874956956598908\n",
      "175 -0.30999955045990646\n",
      "176 -0.6699994973605499\n",
      "177 -1.064999426016584\n",
      "178 -1.053749438840896\n",
      "179 -0.9974994491785765\n",
      "180 -0.8074994613416493\n",
      "181 -0.6974994633346796\n",
      "182 -0.5874994919868186\n",
      "183 -0.7087494925362989\n",
      "184 -0.9887494549620897\n",
      "185 -0.9187494548968971\n",
      "186 -0.5662495369324461\n",
      "187 -0.5112495522480458\n",
      "188 -0.7287494789343327\n",
      "189 -0.20249956392217427\n",
      "190 -0.14874955802224576\n",
      "191 -0.3249995345249772\n",
      "192 -0.23749954241793603\n",
      "193 -0.22124952648300678\n",
      "194 0.12125037098303437\n",
      "195 0.2900003537652083\n",
      "196 -0.4312495426274836\n",
      "197 0.0362504234071821\n",
      "198 -0.14374957128893584\n",
      "199 -0.4687495398102328\n",
      "200 -0.17249953956343234\n",
      "201 0.3525003851391375\n",
      "202 1.0225002722581849\n",
      "203 0.016250385204330087\n",
      "204 0.751250320696272\n",
      "205 0.5612503255251795\n",
      "206 0.6462503494694829\n",
      "207 0.6275003112968989\n",
      "208 0.5250003201072104\n",
      "209 0.1225003550061956\n",
      "210 -0.826249455101788\n",
      "211 -0.3849995564087294\n",
      "212 -0.7362494895933196\n",
      "213 -0.6537494901567698\n",
      "214 -0.1687495653750375\n",
      "215 0.5950003552716225\n",
      "216 -0.08249958313535899\n",
      "217 0.5712503534159623\n",
      "218 1.371250269585289\n",
      "219 0.7725002890219912\n",
      "220 0.17625037231482565\n",
      "221 0.11625037156045437\n",
      "222 0.32875036529731005\n",
      "223 0.6900003146147355\n",
      "224 0.11875038768630475\n",
      "225 0.15250039054080844\n",
      "226 0.3587503610178828\n",
      "227 0.511250336188823\n",
      "228 0.08250040223356336\n",
      "229 -0.3299995572306216\n",
      "230 1.1387502498691902\n",
      "231 0.2900003175018355\n",
      "232 -0.8662494663149118\n",
      "233 0.5287502669962123\n",
      "234 -0.10749960649991408\n",
      "235 -0.6862494791857898\n",
      "236 -0.03249958634842187\n",
      "237 -0.24624953547026962\n",
      "238 0.42750040837563574\n",
      "239 0.7012503281002864\n",
      "240 0.9737502471543849\n",
      "241 0.3800003599608317\n",
      "242 0.1825003888225183\n",
      "243 -0.20374956692103297\n",
      "244 -0.2712495248997584\n",
      "245 -0.2737495295004919\n",
      "246 -0.28624957252759486\n",
      "247 -0.6687494707293808\n",
      "248 0.017500415968243033\n",
      "249 0.3950003714999184\n",
      "250 -0.23624957574065775\n",
      "251 -0.01999956334475428\n",
      "252 -0.16624956240411848\n",
      "253 -0.4312495494959876\n",
      "254 -1.0899994312785566\n",
      "255 -0.03499953367281705\n",
      "256 0.49375036626588553\n",
      "257 0.30250038451049477\n",
      "258 0.4600003600353375\n",
      "259 0.05625042202882469\n",
      "260 -0.008749619650188833\n",
      "261 -0.9687494607642293\n",
      "262 0.5500003314809874\n",
      "263 -0.31624958268366754\n",
      "264 -0.8037494736490771\n",
      "265 -0.39874954870902\n",
      "266 -0.8024994678562507\n",
      "267 -0.7462494608480483\n",
      "268 -0.8937494596466422\n",
      "269 -0.6274995132116601\n",
      "270 -0.8012494524009526\n",
      "271 -0.38749950856436044\n",
      "272 -0.0237495832843706\n",
      "273 -0.119999552029185\n",
      "274 -0.23749954713275656\n",
      "275 -0.5799995030974969\n",
      "276 -0.7387494589202106\n",
      "277 -0.8912494471296668\n",
      "278 -0.8112494754604995\n",
      "279 -0.7474994619842619\n",
      "280 0.45125037885736674\n",
      "281 0.3600004018517211\n",
      "282 1.2150002081179991\n",
      "283 0.043750411830842495\n",
      "284 -1.0862494255416095\n",
      "285 -0.7099994912277907\n",
      "286 -0.8349994770251215\n",
      "287 -0.8312494566198438\n",
      "288 -0.4062495135003701\n",
      "289 -0.7674994729459286\n",
      "290 -0.1037495550699532\n",
      "291 -0.33374955999897793\n",
      "292 -0.2724995685275644\n",
      "293 -0.20749954204075038\n",
      "294 -0.18624958145665005\n",
      "295 0.02000042493455112\n",
      "296 -0.26874954596860334\n",
      "297 -0.6037494952324778\n",
      "298 0.2187503803288564\n",
      "299 0.05125042865984142\n",
      "300 -0.39499950816389173\n",
      "301 -0.4737495169392787\n",
      "302 -0.42749951558653265\n",
      "303 -0.6949994787573814\n",
      "304 -0.5749995259102434\n",
      "305 -0.3749995286343619\n",
      "306 0.25750039250124246\n",
      "307 0.80000023113098\n",
      "308 -0.6062494996003807\n",
      "309 0.5337503515183926\n",
      "310 0.33375034609343857\n",
      "311 0.10875044425483793\n",
      "312 -0.5099995158379897\n",
      "313 0.17625039571430534\n",
      "314 0.865000261226669\n",
      "315 -0.14374956244137138\n",
      "316 0.16875038400758058\n",
      "317 -0.2812495193211362\n",
      "318 -0.5249995299382135\n",
      "319 -0.9762494615861215\n",
      "320 0.21125041285995394\n",
      "321 0.03250037331599742\n",
      "322 0.17750038858503103\n",
      "323 -0.4312495308695361\n",
      "324 -0.7049995001871139\n",
      "325 0.44750032969750464\n",
      "326 0.11750035616569221\n",
      "327 0.20125038654077798\n",
      "328 0.46375033480580896\n",
      "329 0.051250383898150176\n",
      "330 -0.33249954727943987\n",
      "331 0.5462503479793668\n",
      "332 0.6575003052130342\n",
      "333 -0.011249595554545522\n",
      "334 0.2925003804266453\n",
      "335 0.023750402498990297\n",
      "336 -0.32249955541919917\n",
      "337 -0.05124958971282467\n",
      "338 0.6975003421539441\n",
      "339 0.7175002828007564\n",
      "340 0.5587503215647303\n",
      "341 0.15125039650592953\n",
      "342 0.10375040990766138\n",
      "343 0.7125002966495231\n",
      "344 0.2937503802822903\n",
      "345 -0.6087495201500133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346 -0.5262495080241933\n",
      "347 -0.39374951482750475\n",
      "348 -0.018749581882730126\n",
      "349 -0.1299995550652966\n",
      "350 0.20250037091318518\n",
      "351 0.3975003713276237\n",
      "352 -0.10124957520747557\n",
      "353 -0.16374956211075187\n",
      "354 0.44750035367906094\n",
      "355 0.14000039611710235\n",
      "356 0.8062502890825272\n",
      "357 0.40750035422388464\n",
      "358 0.25125037354882807\n",
      "359 -0.07874957559397444\n",
      "360 0.1387504009762779\n",
      "361 0.053750431863591075\n",
      "362 -0.03374957386404276\n",
      "363 0.6912503127241507\n",
      "364 0.2400003969669342\n",
      "365 -0.12874955299776047\n",
      "366 0.6850003151921555\n",
      "367 -0.39749953674618155\n",
      "368 0.3575003477744758\n",
      "369 0.17250036855693907\n",
      "370 0.3262503327568993\n",
      "371 0.36000037798658013\n",
      "372 -0.12374956288840622\n",
      "373 -0.14999954646918923\n",
      "374 0.07750043843407184\n",
      "375 0.37125033780466765\n",
      "376 0.2525003715418279\n",
      "377 -0.1049995586508885\n",
      "378 0.3800003584474325\n",
      "379 0.44750036275945604\n",
      "380 0.2725003749364987\n",
      "381 -0.402499548625201\n",
      "382 0.1300003957003355\n",
      "383 -0.20124955888604745\n",
      "384 0.3837503948016092\n",
      "385 0.40375038306228817\n",
      "386 0.10750035208184272\n",
      "387 -0.2237495587905869\n",
      "388 0.04250041802879423\n",
      "389 -0.14249957248102874\n",
      "390 0.172500392771326\n",
      "391 0.5087503533577546\n",
      "392 0.39625033864285797\n",
      "393 0.5362503194482997\n",
      "394 0.5375003563822247\n",
      "395 1.7912501755054109\n",
      "396 1.2075002316851169\n",
      "397 -0.05874956981278956\n",
      "398 0.7812503032619134\n",
      "399 0.35125035513192415\n",
      "400 -0.14999955310486257\n",
      "401 -0.4049995419336483\n",
      "402 0.2975003784522414\n",
      "403 0.8187503021908924\n",
      "404 -0.20249959325883538\n",
      "405 0.8275002716691233\n",
      "406 -0.5337495114654303\n",
      "407 0.03875039954436943\n",
      "408 -0.019999585230834782\n",
      "409 0.8487502714269795\n",
      "410 0.6775003060465679\n",
      "411 0.2737503523239866\n",
      "412 0.40000032423995435\n",
      "413 0.23250036500394344\n",
      "414 -1.0274994289502501\n",
      "415 -1.0612494284287095\n",
      "416 -0.9412494623102248\n",
      "417 -0.26124956167768687\n",
      "418 -0.8962494694278575\n",
      "419 -0.4362495258683339\n",
      "420 -0.19874954666011035\n",
      "421 0.09000040788669139\n",
      "422 -0.28124957089312375\n",
      "423 -0.16499958437634632\n",
      "424 -1.0087494478793815\n",
      "425 -0.09499957686057314\n",
      "426 0.043750395299866796\n",
      "427 -0.40124951367033646\n",
      "428 0.1162504032254219\n",
      "429 0.35125037585385144\n",
      "430 0.5662503783823922\n",
      "431 -0.09499959787353873\n",
      "432 0.223750383942388\n",
      "433 -0.34999953175429255\n",
      "434 -0.5699994972674176\n",
      "435 -0.30499951587989926\n",
      "436 0.14375040115555748\n",
      "437 0.1662504042033106\n",
      "438 -0.11624953569844365\n",
      "439 0.1437503844499588\n",
      "440 0.6537502973224036\n",
      "441 -0.008749593747779727\n",
      "442 -0.02749956160550937\n",
      "443 0.34000034735072404\n",
      "444 0.5550002792151645\n",
      "445 -0.8762494671391323\n",
      "446 -0.08124957256950438\n",
      "447 0.3575003480655141\n",
      "448 0.1875003741006367\n",
      "449 0.2312503510620445\n",
      "450 0.31125035881996155\n",
      "451 -0.8299994552507997\n",
      "452 -0.27749953872989863\n",
      "453 0.14875037921592593\n",
      "454 -0.09249954822007567\n",
      "455 -0.8987494520843029\n",
      "456 0.1600004155188799\n",
      "457 -0.06374957540538162\n",
      "458 0.017500399611890316\n",
      "459 -0.564999527123291\n",
      "460 -0.4024995443178341\n",
      "461 -0.3437495459802449\n",
      "462 -0.6787494863383472\n",
      "463 -0.8212494750041515\n",
      "464 -0.5137495114468038\n",
      "465 -0.878749449388124\n",
      "466 -0.47749950375873595\n",
      "467 -0.3199995424365625\n",
      "468 0.5025003484333865\n",
      "469 0.5162503068568185\n",
      "470 0.2862504104850814\n",
      "471 0.4412503659259528\n",
      "472 -0.5712495309999213\n",
      "473 -0.6062495077494532\n",
      "474 -0.04499956872314215\n",
      "475 0.2775003766291775\n",
      "476 -0.687499497900717\n",
      "477 -0.4049995366949588\n",
      "478 -0.19249955844134092\n",
      "479 0.1550003932788968\n",
      "480 0.3250003366265446\n",
      "481 -0.7674994670087472\n",
      "482 -1.0274994457722642\n",
      "483 -0.15249952173326164\n",
      "484 -0.19999957946129143\n",
      "485 0.02000038663391024\n",
      "486 -0.48624953418038785\n",
      "487 0.16750039625912905\n",
      "488 0.22250038315542042\n",
      "489 0.14500040863640606\n",
      "490 -0.18624954210827127\n",
      "491 0.44125034683384\n",
      "492 1.1312502138316631\n",
      "493 0.21500039257807657\n",
      "494 0.5662503190105781\n",
      "495 -0.07874959288164973\n",
      "496 0.03375039080856368\n",
      "497 -0.4224995606346056\n",
      "498 -0.3549995271023363\n",
      "499 -0.4737495171139017\n",
      "500 0.2187504072790034\n",
      "501 -0.5062494913581759\n",
      "502 0.0025004077469930053\n",
      "503 -0.5524994907900691\n",
      "504 -0.3512495383620262\n",
      "505 -0.16749954759143293\n",
      "506 0.13375037256628275\n",
      "507 0.6062502858112566\n",
      "508 0.3775003377813846\n",
      "509 -0.43749953736551106\n",
      "510 0.44750035903416574\n",
      "511 0.9300002806121483\n",
      "512 -0.22874954948201776\n",
      "513 -0.15124954795464873\n",
      "514 -0.5149995073443279\n",
      "515 0.11000041209626943\n",
      "516 -1.0412494288757443\n",
      "517 0.018750446033664048\n",
      "518 0.14875041285995394\n",
      "519 0.20750035188393667\n",
      "520 -0.5174994947155938\n",
      "521 0.11875040282029659\n",
      "522 -0.3624995332211256\n",
      "523 -0.41249954589875415\n",
      "524 -0.2424995640758425\n",
      "525 -0.12499958882108331\n",
      "526 0.7812503211898729\n",
      "527 0.46625036181649193\n",
      "528 -0.04749955877196044\n",
      "529 -0.30374958482570946\n",
      "530 -0.08374959864886478\n",
      "531 0.29750038305064663\n",
      "532 0.4700003154575825\n",
      "533 0.558750351308845\n",
      "534 -0.05624958232510835\n",
      "535 -0.42374953301623464\n",
      "536 0.3837503695394844\n",
      "537 0.6650003168033436\n",
      "538 0.5287503536674194\n",
      "539 1.3625002081971616\n",
      "540 0.9350002020946704\n",
      "541 -0.8212494812905788\n",
      "542 1.4712501853937283\n",
      "543 0.8287502861348912\n",
      "544 -0.10874958359636366\n",
      "545 0.5187503721099347\n",
      "546 0.5750003323191777\n",
      "547 -0.308749541756697\n",
      "548 -0.01874956052051857\n",
      "549 0.4775003573158756\n",
      "550 -0.9187494528014213\n",
      "551 -0.08749956305837259\n",
      "552 0.49125034362077713\n",
      "553 -0.21374954842031002\n",
      "554 0.28750035108532757\n",
      "555 0.016250407847110182\n",
      "556 -0.5099995755590498\n",
      "557 0.19125041586812586\n",
      "558 -0.4949995413189754\n",
      "559 -0.1537495560478419\n",
      "560 0.25875034846831113\n",
      "561 0.26500039151869714\n",
      "562 0.27250036800978705\n",
      "563 -0.24499954184284434\n",
      "564 -0.03374956373590976\n",
      "565 0.12250038678757846\n",
      "566 -0.1962495620828122\n",
      "567 0.5187503393972293\n",
      "568 0.43000035372097045\n",
      "569 0.9525002938462421\n",
      "570 0.7487503375159577\n",
      "571 0.7200002990430221\n",
      "572 0.13875036587705836\n",
      "573 0.06125038699246943\n",
      "574 0.14625042164698243\n",
      "575 -0.17124956264160573\n",
      "576 0.133750380249694\n",
      "577 -0.48374953283928335\n",
      "578 -0.42374950367957354\n",
      "579 -0.22249955066945404\n",
      "580 0.3375003640539944\n",
      "581 -0.0024995385319925845\n",
      "582 -0.038749572704546154\n",
      "583 0.16375039948616177\n",
      "584 0.34875038592144847\n",
      "585 1.0537502556690015\n",
      "586 0.5737503460259177\n",
      "587 -0.5937494938261807\n",
      "588 -0.622499497490935\n",
      "589 -0.04124963009962812\n",
      "590 -0.10124955518404022\n",
      "591 0.16500039480160922\n",
      "592 0.5087503656395711\n",
      "593 0.21000034548342228\n",
      "594 0.02125039731618017\n",
      "595 -0.47249953489517793\n",
      "596 -0.36749950429657474\n",
      "597 0.6075002964353189\n",
      "598 0.2662503590108827\n",
      "599 -0.09499957133084536\n",
      "600 0.2037504055770114\n",
      "601 -0.0024995659478008747\n",
      "602 0.04500037233810872\n",
      "603 0.09750037640333176\n",
      "604 0.30125038197729737\n",
      "605 0.7625002819113433\n",
      "606 -0.5099995206110179\n",
      "607 -0.34999954572413117\n",
      "608 -0.6549995148088783\n",
      "609 -0.39999951503705233\n",
      "610 0.1062503611901775\n",
      "611 -0.26874954940285534\n",
      "612 0.32625036546960473\n",
      "613 0.240000365243759\n",
      "614 0.18500036711338907\n",
      "615 0.7337503202725202\n",
      "616 -0.0887496056384407\n",
      "617 0.09500041941646487\n",
      "618 1.395000203687232\n",
      "619 -0.367499558837153\n",
      "620 0.5212503251386806\n",
      "621 0.1500003607943654\n",
      "622 0.3075003466219641\n",
      "623 0.40375033882446587\n",
      "624 -0.20499955874402076\n",
      "625 -0.24874953064136207\n",
      "626 0.43500033317832276\n",
      "627 0.41000033100135624\n",
      "628 -0.7149994813953526\n",
      "629 -0.24249953625258058\n",
      "630 -0.0162495921831578\n",
      "631 0.06125041202176362\n",
      "632 1.1662502026301809\n",
      "633 0.20000041369348764\n",
      "634 0.22625037701800466\n",
      "635 0.1137504322687164\n",
      "636 0.28375036222860217\n",
      "637 0.42250033176969737\n",
      "638 -1.0849994239397347\n",
      "639 -0.013749570760410279\n",
      "640 0.48000034294091165\n",
      "641 0.16000042983796448\n",
      "642 -0.20749957155203447\n",
      "643 -0.2849995455471799\n",
      "644 -0.16624954191502184\n",
      "645 -0.043749582720920444\n",
      "646 0.29375037213321775\n",
      "647 -0.612499512732029\n",
      "648 -0.12499960965942591\n",
      "649 -0.12249956978484988\n",
      "650 -0.4512495156377554\n",
      "651 0.4612503583775833\n",
      "652 -0.38624953222461045\n",
      "653 -0.44624951609876007\n",
      "654 0.24000036006327718\n",
      "655 0.058750371739733964\n",
      "656 -0.636249500210397\n",
      "657 0.06250043003819883\n",
      "658 0.09500040172133595\n",
      "659 1.1725002442253754\n",
      "660 -0.24749957385938615\n",
      "661 0.3450003308826126\n",
      "662 -0.1449995336588472\n",
      "663 0.08375038986559957\n",
      "664 0.47750035382341594\n",
      "665 0.9400002834154293\n",
      "666 -0.5149995182873681\n",
      "667 -0.018749575247056782\n",
      "668 -0.2937495717778802\n",
      "669 -0.5149994980311021\n",
      "670 -0.2912495955824852\n",
      "671 0.17875037027988583\n",
      "672 -0.047499580890871584\n",
      "673 -0.4199995354283601\n",
      "674 0.08500040275976062\n",
      "675 0.2575003730598837\n",
      "676 -0.9424994615837932\n",
      "677 0.13250038877595216\n",
      "678 -0.4312495398335159\n",
      "679 0.5762503501609899\n",
      "680 0.4600003568921238\n",
      "681 -0.47999950824305415\n",
      "682 -0.6749994985293597\n",
      "683 -0.35374954307917506\n",
      "684 -0.5137495229719207\n",
      "685 0.14875042263884097\n",
      "686 0.6200003193807788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 -0.1924995438894257\n",
      "688 -0.6662494710180908\n",
      "689 -0.3712495600921102\n",
      "690 -0.8562494551297277\n",
      "691 0.706250335671939\n",
      "692 0.8887503007426858\n",
      "693 0.6187503018882126\n",
      "694 0.6325003289966844\n",
      "695 -0.5424995174398646\n",
      "696 -0.2999995517311618\n",
      "697 -0.05749958899104968\n",
      "698 -0.23249958420637995\n",
      "699 -0.15499960188753903\n",
      "700 0.29375039343722165\n",
      "701 -0.08124959853012115\n",
      "702 0.5150003379676491\n",
      "703 0.5712503356626257\n",
      "704 -0.5649994827108458\n",
      "705 0.012500391341745853\n",
      "706 0.21875038591679186\n",
      "707 -0.28124955482780933\n",
      "708 -0.4449995117029175\n",
      "709 -0.19249956880230457\n",
      "710 -0.0849995817989111\n",
      "711 0.25000037031713873\n",
      "712 0.7600003165425733\n",
      "713 0.05250038916710764\n",
      "714 -0.5337495136773214\n",
      "715 -0.1787495791213587\n",
      "716 0.3450003626057878\n",
      "717 -0.3037495502503589\n",
      "718 -0.7174994815140963\n",
      "719 -0.32249954488361254\n",
      "720 0.06000041007064283\n",
      "721 -0.7374994778074324\n",
      "722 -0.18624953518155962\n",
      "723 -0.48374950198922306\n",
      "724 -0.08624957216670737\n",
      "725 0.11375040333950892\n",
      "726 -0.16999958571977913\n",
      "727 -0.19249954272527248\n",
      "728 -0.4512495083035901\n",
      "729 -0.2124995625927113\n",
      "730 0.06750041770283133\n",
      "731 0.9500002997228876\n",
      "732 0.06375036662211642\n",
      "733 1.1062502714339644\n",
      "734 1.068750303471461\n",
      "735 0.6662503541447222\n",
      "736 -0.17499953700462356\n",
      "737 0.11125038680620492\n",
      "738 -0.2562495310558006\n",
      "739 -0.0849995797034353\n",
      "740 0.6362503109266981\n",
      "741 0.8437503103050403\n",
      "742 0.5837503227521665\n",
      "743 0.7637502949219197\n",
      "744 0.31500035990029573\n",
      "745 -0.03999960329383612\n",
      "746 0.3100003460422158\n",
      "747 -0.881249462836422\n",
      "748 -0.5212495035957545\n",
      "749 0.2587503417744301\n",
      "750 0.8462502674665302\n",
      "751 0.38000033143907785\n",
      "752 -0.41749953536782414\n",
      "753 -0.49124951323028654\n",
      "754 -0.09374953829683363\n",
      "755 0.5750003232387826\n",
      "756 -0.35874952923040837\n",
      "757 -0.0374995976453647\n",
      "758 -0.18874956970103085\n",
      "759 0.12875038979109377\n",
      "760 0.027500423369929194\n",
      "761 0.5750003169523552\n",
      "762 0.3525003653485328\n",
      "763 -0.08124959521228448\n",
      "764 -0.056249604909680784\n",
      "765 -0.2212495394051075\n",
      "766 0.4337503664428368\n",
      "767 0.4500003387220204\n",
      "768 -0.1599995642900467\n",
      "769 -1.0449994430528022\n",
      "770 -0.19624954799655825\n",
      "771 -0.10249957570340484\n",
      "772 0.23375036410288885\n",
      "773 -0.5587495387298986\n",
      "774 -0.2274995879852213\n",
      "775 0.11375039367703721\n",
      "776 -0.03624958544969559\n",
      "777 -0.07874959497712553\n",
      "778 0.22875036904588342\n",
      "779 0.290000366687309\n",
      "780 -0.16124954633414745\n",
      "781 0.7825002897297964\n",
      "782 -0.24624954798491672\n",
      "783 -0.3274995475076139\n",
      "784 -0.06624956912128255\n",
      "785 -0.6449995123548433\n",
      "786 -0.34124954999424517\n",
      "787 -0.6212494944338687\n",
      "788 -0.4287494954187423\n",
      "789 0.47375035285949707\n",
      "790 0.15125034673837945\n",
      "791 -0.07999958388973027\n",
      "792 -0.8037494901800528\n",
      "793 -0.6424994897097349\n",
      "794 -0.7862494621658698\n",
      "795 -0.3449995490955189\n",
      "796 -0.1549995599198155\n",
      "797 -0.3487495183944702\n",
      "798 -0.489999535784591\n",
      "799 -0.941249467083253\n",
      "800 -0.24749956035520881\n",
      "801 -0.7349994846736081\n",
      "802 -0.44499950238969177\n",
      "803 0.6962502864189446\n",
      "804 -0.17374956188723445\n",
      "805 0.27500036358833313\n",
      "806 -0.4849995144177228\n",
      "807 -0.477499540313147\n",
      "808 -0.5887494854396209\n",
      "809 -0.402499528368935\n",
      "810 -0.30749952944461256\n",
      "811 -0.5312495249090716\n",
      "812 -0.5187495065620169\n",
      "813 -0.712499491928611\n",
      "814 -0.5537495020544156\n",
      "815 0.5825003457721323\n",
      "816 -0.12124955898616463\n",
      "817 -0.6399994933744892\n",
      "818 0.3837503961985931\n",
      "819 0.03500038001220673\n",
      "820 0.30500034673605114\n",
      "821 0.06875042704632506\n",
      "822 -0.302499528741464\n",
      "823 -0.08374957263004035\n",
      "824 0.07875039579812437\n",
      "825 -0.10374958906322718\n",
      "826 -0.1324995714239776\n",
      "827 -0.35499955783598125\n",
      "828 0.22625040879938751\n",
      "829 0.24500034761149436\n",
      "830 0.030000390950590372\n",
      "831 0.33125035476405174\n",
      "832 -0.029999574355315417\n",
      "833 -0.4524995153769851\n",
      "834 0.5175003298209049\n",
      "835 0.16375039948616177\n",
      "836 0.682500341325067\n",
      "837 0.4162503513507545\n",
      "838 -0.6512494848575443\n",
      "839 0.3137503549223766\n",
      "840 0.017500418587587774\n",
      "841 -0.7249994965968654\n",
      "842 -0.44999951001955196\n",
      "843 -0.4637495233910158\n",
      "844 0.16375040222192183\n",
      "845 0.28625034680590034\n",
      "846 -0.4499995317310095\n",
      "847 0.13125040743034333\n",
      "848 -0.02499957208056003\n",
      "849 0.007500419858843088\n",
      "850 -0.24249953962862492\n",
      "851 1.038750252511818\n",
      "852 0.226250400650315\n",
      "853 -0.10999955353327096\n",
      "854 0.465000367956236\n",
      "855 -0.19749957940075547\n",
      "856 0.26875037024728954\n",
      "857 -0.2499995618709363\n",
      "858 -0.23624951753299683\n",
      "859 -0.17374952719546854\n",
      "860 0.2300003619166091\n",
      "861 0.2650003820890561\n",
      "862 0.3375003468245268\n",
      "863 -0.6799994788598269\n",
      "864 0.6237503367010504\n",
      "865 -0.3762495449045673\n",
      "866 -0.003749602474272251\n",
      "867 -1.0762494280934334\n",
      "868 -0.05999957036692649\n",
      "869 -0.3324995504808612\n",
      "870 -0.848749456461519\n",
      "871 0.10875042038969696\n",
      "872 0.0337503677001223\n",
      "873 0.07875038415659219\n",
      "874 0.19125036895275116\n",
      "875 0.4625003474066034\n",
      "876 -0.24124958564061671\n",
      "877 0.7212502919137478\n",
      "878 -0.9987494521774352\n",
      "879 -0.21999954141210765\n",
      "880 -0.17249953956343234\n",
      "881 0.6062503296416253\n",
      "882 0.7387503032805398\n",
      "883 0.29875036946032196\n",
      "884 -0.5449995091184974\n",
      "885 -0.26624956651357934\n",
      "886 0.7387503064237535\n",
      "887 0.18625036656158045\n",
      "888 0.670000322512351\n",
      "889 0.008750397886615247\n",
      "890 0.5987503307987936\n",
      "891 0.12000041280407459\n",
      "892 -0.07374959078151733\n",
      "893 -0.28249956673244014\n",
      "894 0.3487503577489406\n",
      "895 -0.21249957050895318\n",
      "896 -0.7874994780868292\n",
      "897 -0.8587494563544169\n",
      "898 -1.011249449569732\n",
      "899 -0.6087494964012876\n",
      "900 -0.5737495080102235\n",
      "901 -0.33124951540958136\n",
      "902 0.22625038551632315\n",
      "903 0.21500038751401007\n",
      "904 -0.5462494801031426\n",
      "905 -0.07999958307482302\n",
      "906 -0.10374956275336444\n",
      "907 -0.09874956670682877\n",
      "908 -0.41749953373800963\n",
      "909 -0.3874995334772393\n",
      "910 0.5587502996786498\n",
      "911 0.5350003307685256\n",
      "912 1.161250292614568\n",
      "913 -0.3499995121965185\n",
      "914 0.21500033524353057\n",
      "915 0.18000038713216782\n",
      "916 -0.52874950109981\n",
      "917 -0.48249952105106786\n",
      "918 0.23000036366283894\n",
      "919 -0.3087495496729389\n",
      "920 -0.5287495283409953\n",
      "921 -0.7462494977517053\n",
      "922 -0.8324994760332629\n",
      "923 0.08500039263162762\n",
      "924 1.1187502465909347\n",
      "925 1.2925002062111162\n",
      "926 0.33250038768164814\n",
      "927 0.5250003224937245\n",
      "928 -0.2549995156005025\n",
      "929 -0.7037494673859328\n",
      "930 -0.29124954668805003\n",
      "931 0.5850003706291318\n",
      "932 0.6225003245053813\n",
      "933 0.22625035629607737\n",
      "934 -0.6387495432281867\n",
      "935 -0.14624955772887915\n",
      "936 0.5000003582099453\n",
      "937 -0.021249599056318402\n",
      "938 -0.11124957317952067\n",
      "939 -0.9474994570482522\n",
      "940 -0.3987495122710243\n",
      "941 -0.15249954827595502\n",
      "942 -0.12874958291649818\n",
      "943 -0.42499952646903694\n",
      "944 -1.0899994256906211\n",
      "945 0.3387503477279097\n",
      "946 0.5800003486219794\n",
      "947 -0.061249607359059155\n",
      "948 -0.6137494785944\n",
      "949 0.2000004017027095\n",
      "950 0.9900002613430843\n",
      "951 0.8925002817995846\n",
      "952 0.006250393344089389\n",
      "953 -0.7774994904175401\n",
      "954 -0.44124952831771225\n",
      "955 -0.22624952078331262\n",
      "956 0.47375030867988244\n",
      "957 -0.272499559330754\n",
      "958 0.03375042008701712\n",
      "959 0.1812503922265023\n",
      "960 0.6475003253435716\n",
      "961 0.11125037772580981\n",
      "962 0.37500039825681597\n",
      "963 0.4800002973061055\n",
      "964 0.3775003642658703\n",
      "965 -0.15374957147287205\n",
      "966 0.12875040428480133\n",
      "967 -0.4724995221477002\n",
      "968 -0.12374958419241011\n",
      "969 -0.3899995310930535\n",
      "970 -0.5974994716234505\n",
      "971 -0.20499954896513373\n",
      "972 -0.21249956381507218\n",
      "973 -0.37499954574741423\n",
      "974 -0.4262495263828896\n",
      "975 -0.017499553156085312\n",
      "976 0.20000035408884287\n",
      "977 0.27250035264296457\n",
      "978 -0.1962495379266329\n",
      "979 0.005000401055440307\n",
      "980 -0.026249582297168672\n",
      "981 -0.17374957288848236\n",
      "982 -0.3599995644763112\n",
      "983 -0.15874956990592182\n",
      "984 -0.28624958044383675\n",
      "985 0.023750436841510236\n",
      "986 -0.16999956290237606\n",
      "987 0.35500038194004446\n",
      "988 -0.624999510939233\n",
      "989 0.21250039350707084\n",
      "990 0.31625039654318243\n",
      "991 0.36250036966521293\n",
      "992 0.3750003862660378\n",
      "993 0.3550003207055852\n",
      "994 0.5112503609852865\n",
      "995 0.19500036223325878\n",
      "996 -0.29874953639227897\n",
      "997 -0.3037495577009395\n",
      "998 -0.5162495122058317\n",
      "999 0.1800004084361717\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    #Reset agent\n",
    "    agent.reset()\n",
    "    env.reset()\n",
    "\n",
    "    #Agent set\n",
    "    agent_scores = np.zeros(num_agents)\n",
    "    step_result = env.get_step_result(group_name)\n",
    "    states = step_result.obs[0]\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        \n",
    "        #[Tanh - 1 1]\n",
    "        actions = agent.act(states)\n",
    "        \n",
    "#         if np.random.uniform() < 0.05: \n",
    "#             print(actions)\n",
    "        \n",
    "        # actions\n",
    "        env.set_actions(group_name, actions)\n",
    "        env.step()\n",
    "        step_result = env.get_step_result(group_name)\n",
    "        next_states = step_result.obs[0]\n",
    "\n",
    "        rewards = step_result.reward\n",
    "        dones = step_result.done\n",
    "\n",
    "        #learn\n",
    "        if _ > 10:\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "        \n",
    "        states = next_states\n",
    "        #print(\"t\",rewards)\n",
    "        agent_scores += rewards[0:num_agents]\n",
    "        \n",
    "        #done\n",
    "        done = step_result.done[0]\n",
    "\n",
    "\n",
    "    print(_,np.mean(agent_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset()\n",
    "# step_result = env.get_step_result(group_name)\n",
    "# done = False\n",
    "# episode_rewards = 0\n",
    "# while not done:\n",
    "#     action_size = group_spec.action_size\n",
    "#     if group_spec.is_action_continuous():\n",
    "#         action = np.random.randn(step_result.n_agents(), group_spec.action_size)\n",
    "\n",
    "#     if group_spec.is_action_discrete():\n",
    "#         branch_size = group_spec.discrete_action_branches\n",
    "#         action = np.column_stack([np.random.randint(0, branch_size[i], size=(step_result.n_agents())) for i in range(len(branch_size))])\n",
    "#     env.set_actions(group_name, action)\n",
    "#     env.step()\n",
    "#     step_result = env.get_step_result(group_name)\n",
    "#     episode_rewards += step_result.reward[0]\n",
    "#     done = step_result.done[0]\n",
    "# print(\"Total reward this episode: {}\".format(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: 0.785000360570848\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -0.38499961514025927\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: 1.2250001365318894\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.0649994472041726\n",
      "Total reward this episode: -0.4849996091797948\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -0.9449994871392846\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: 0.35500022768974304\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -0.45499951858073473\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: 2.4549999739974737\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -0.6249995091930032\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.0649994472041726\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.0649994472041726\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: 0.7850001975893974\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -0.09499953407794237\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -1.1049994202330709\n",
      "Total reward this episode: -0.9849995011463761\n"
     ]
    }
   ],
   "source": [
    "for episode in range(100):\n",
    "    env.reset()\n",
    "    step_result = env.get_step_result(group_name)\n",
    "    done = False\n",
    "    episode_rewards = 0\n",
    "    while not done:\n",
    "        action_size = group_spec.action_size\n",
    "        if group_spec.is_action_continuous():\n",
    "            action = np.random.randn(step_result.n_agents(), group_spec.action_size)\n",
    "            \n",
    "        if group_spec.is_action_discrete():\n",
    "            branch_size = group_spec.discrete_action_branches\n",
    "            action = np.column_stack([np.random.randint(0, branch_size[i], size=(step_result.n_agents())) for i in range(len(branch_size))])\n",
    "        env.set_actions(group_name, action)\n",
    "        env.step()\n",
    "        step_result = env.get_step_result(group_name)\n",
    "        episode_rewards += step_result.reward[0]\n",
    "        done = step_result.done[0]\n",
    "    print(\"Total reward this episode: {}\".format(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
