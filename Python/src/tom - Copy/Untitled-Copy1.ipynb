{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\courses\\\\aaai2019-master\\\\src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"E:\\\\courses\\\\aaai2019-master\\\\src\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Local imports\n",
    "import tom.config\n",
    "import tom.render_utils\n",
    "from tom.tom_agents import ToMAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    paths = tom.config.Paths()\n",
    "    exp_name = tom.config.exp_name\n",
    "    episodes = tom.config.episodes\n",
    "    episode_len = tom.config.episode_len\n",
    "    save_rate = tom.config.save_rate\n",
    "    method = 'ToM'  # ['chase', 'ToM gt', 'ToM']\n",
    "    debug = False\n",
    "\n",
    "    scenario=\"simple_chase\"\n",
    "    max_episode_len=episode_len\n",
    "    num_episodes=episodes\n",
    "\n",
    "    # Agent setting\n",
    "    method=method\n",
    "\n",
    "    use_gt_belief=True if method == 'ToM gt' else False\n",
    "    direct_chase=True if method == 'chase' else False\n",
    "    use_distance=True\n",
    "\n",
    "    # Checkpoint\n",
    "    exp_name=exp_name\n",
    "    save_dir=os.path.join(paths.tmp_root, 'checkpoints', exp_name, method)\n",
    "    save_rate=save_rate\n",
    "\n",
    "    # Evaluation\n",
    "    debug=debug\n",
    "    restore=False\n",
    "    display=True\n",
    "    display_mode=\"all\"\n",
    "    save_screen=False\n",
    "    benchmark=True\n",
    "    benchmark_iters=episodes\n",
    "    benchmark_dir=os.path.join(paths.tmp_root, 'benchmark', exp_name, method)\n",
    "    plots_dir=os.path.join(paths.tmp_root, 'plots', exp_name, method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24b012d70d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "np.random.seed(int(t_start))\n",
    "torch.manual_seed(int(t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiagent.environment import MultiAgentEnv\n",
    "import multiagent.scenarios as scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simple_chase'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scenario from script\n",
    "scenario = scenarios.load(args.scenario + \".py\").Scenario(open_world=True, setting=args.exp_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create world\n",
    "world = scenario.make_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create multi-agent environment\n",
    "try:\n",
    "    done_callback = scenario.done\n",
    "    info_callback = scenario.info\n",
    "except AttributeError:\n",
    "    done_callback = None\n",
    "    info_callback = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MultiAgentEnv(world, scenario.reset_world, scenario.reward, scenario.observation, done_callback=done_callback,\n",
    "                    info_callback=info_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs_n = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]), array([[-0.25749702,  0.39566539],\n",
       "         [-0.72873884,  0.70000459],\n",
       "         [-0.37623724,  0.99988208]]), array([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "polices = list()\n",
    "for i, policy_agent in enumerate(env.world.policy_agents):\n",
    "    polices.append(ToMAgent(policy_agent, env.world, scenario, new_obs_n[i], args.exp_name, use_gt_belief=args.use_gt_belief, use_distance=args.use_distance, direct_chase=args.direct_chase))\n",
    "if args.restore:\n",
    "    for police in polices:\n",
    "        police.load_model(os.path.join(args.save_dir, sorted(os.listdir(args.save_dir))[-1]))\n",
    "if not args.debug:\n",
    "    os.makedirs(os.path.join(args.save_dir, str(int(t_start))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((0, polices[0].__class__.weight.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record data\n",
    "episode_returns = []\n",
    "episode_info = []\n",
    "episode_estimatio_belief = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for different rendering modes\n",
    "display_modes = tom.render_utils.get_display_modes(args.display_mode)\n",
    "\n",
    "# Initialize saving directories\n",
    "args.plots_dir = os.path.join(args.plots_dir, str(int(t_start)))\n",
    "os.makedirs(os.path.join(args.plots_dir, 'belief_value'))\n",
    "os.makedirs(os.path.join(args.plots_dir, 'dist_value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(arglist, weights, filename1=None, filename2=None):\n",
    "    plt.figure(0)\n",
    "    plt.clf()\n",
    "    sns.barplot(x=np.arange(2), y=weights[-1, :2], color='c')\n",
    "    # plt.ylim(-1.0, 1.0)\n",
    "    if filename1 and not arglist.debug:\n",
    "        plt.savefig(filename1)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.pause(0.001)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    plt.plot(np.arange(weights.shape[1]-3), weights[-1, 3:], color='m')\n",
    "    # plt.ylim(-1.0, 1.0)\n",
    "    if filename2 and not arglist.debug:\n",
    "        plt.savefig(filename2)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.pause(0.001)\n",
    "\n",
    "    # =============================== DEBUG ===============================\n",
    "    # plt.figure(0)\n",
    "    # plt.clf()\n",
    "    # plt.plot(np.arange(2), weights[-1, :2], color='c')\n",
    "    # plt.plot(np.arange(2, weights.shape[1]), weights[-1, 2:], color='m')\n",
    "    # # plt.ylim(-1.0, 1.0)\n",
    "    # plt.savefig(filename1)\n",
    "    # plt.pause(0.001)\n",
    "    pass\n",
    "\n",
    "def plot_avg_return(arglist, episode_returns, filename=None):\n",
    "    plt.figure(3)\n",
    "    # plt.plot(np.arange(len(episode_returns)), episode_returns, 'k')\n",
    "    plt.plot(np.arange(len(episode_returns)), [np.mean(episode_returns[max(0, i-99):i+1]) for i in range(len(episode_returns))], 'r')\n",
    "    plt.xlabel('Number of episodes')\n",
    "    plt.ylabel('Avg return')\n",
    "\n",
    "    if filename:\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.pause(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "print(\"Starting training\")\n",
    "sns.set(style=\"white\", context=\"paper\", palette=\"muted\", color_codes=True)\n",
    "while weights.shape[0] <= 1000:\n",
    "    print(\"episode:\",weights.shape[0])\n",
    "    weights = np.vstack((weights, polices[0].__class__.weight))\n",
    "    print(\"weights\", weights, \"stack\", polices[0].__class__.weight)\n",
    "    if True: #weights.shape[0] % args.save_rate == 0:\n",
    "        plot_weights(args, weights, os.path.join(args.plots_dir, 'belief_value', \"belief_value_{}.png\".format(weights.shape[0])),\n",
    "                     os.path.join(args.plots_dir, 'dist_value', \"dist_value_{}.png\".format(weights.shape[0])))\n",
    "        plot_avg_return(args, episode_returns, os.path.join(args.plots_dir, \"avg_return.png\"))\n",
    "\n",
    "    # Initialization\n",
    "    env.reset()\n",
    "    episode_returns.append(0)\n",
    "    episode_info.append([])\n",
    "    episode_estimatio_belief.append([])\n",
    "    action_n = np.zeros((len(polices), 5))\n",
    "    episode_step = 0\n",
    "    prev_values = np.zeros(len(polices))\n",
    "    for police in polices:\n",
    "        police.initialize()\n",
    "\n",
    "    if args.save_screen:\n",
    "        save_screen_dirs = tom.render_utils.get_save_dirs(display_modes, args.plots_dir, str(weights.shape[0]))\n",
    "\n",
    "    # training each episode\n",
    "    while True:\n",
    "        # get current value\n",
    "        curr_values = [police.compute_value() for police in polices]\n",
    "\n",
    "        # choose action based on current approximation\n",
    "        for i, police in enumerate(polices):\n",
    "            action_n[i] = police.select_action(new_obs_n[i])\n",
    "\n",
    "        # update the environment\n",
    "        new_obs_n, reward_n, done_n, info_n = env.step(action_n)\n",
    "        done = any(done_n)\n",
    "\n",
    "        # FIXME: only record the first agent's history\n",
    "        episode_returns[-1] += reward_n[0]\n",
    "        episode_info[-1].append(info_n['n'][0][0])\n",
    "        episode_estimatio_belief[-1].append(polices[0].belief_mean.detach().squeeze().cpu().numpy()[0])\n",
    "\n",
    "        # get next value\n",
    "        next_values = [police.compute_value() for police in polices]\n",
    "        if not args.restore:\n",
    "            for i, police in enumerate(polices):\n",
    "                police.train(reward_n[i], done, prev_values[i], curr_values[i], next_values[i], new_obs_n[i])\n",
    "        prev_values = next_values\n",
    "\n",
    "        thief = env.world.thieves[0]\n",
    "        # for displaying learned policies\n",
    "        if args.display:\n",
    "            # time.sleep(0.1)\n",
    "            tom.render_utils.render_image(env, args.display_mode, thief.belief, True)\n",
    "\n",
    "        # Save screen\n",
    "        if args.save_screen:\n",
    "            for i, d in enumerate(display_modes):\n",
    "                filename = os.path.join(save_screen_dirs[i], \"step{}.png\".format(episode_step))\n",
    "                tom.render_utils.save_screen(env, d, filename, belief=thief.belief)\n",
    "\n",
    "        episode_step += 1\n",
    "        if done or episode_step >= args.max_episode_len:\n",
    "            episode_info[-1].append(done)\n",
    "            break\n",
    "\n",
    "        # End episode loop\n",
    "\n",
    "    if not args.debug:\n",
    "        # Save trained model every few training steps\n",
    "        if weights.shape[0] % args.save_rate == 0:\n",
    "            polices[0].save_model(os.path.join(args.save_dir, str(int(t_start))))\n",
    "\n",
    "    # End training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.paths.tmp_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.plots_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "    actions = np.zeros((5, 5))\n",
    "    actions[np.arange(5), [0, 1, 2, 3, 4]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
